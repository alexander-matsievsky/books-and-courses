{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preface\n",
    "\n",
    "> Our model of the tools needed in a typical data science project looks something like this:\n",
    ">\n",
    "> <img width=\"800\" src=\"https://web.archive.org/web/20201225121014if_/https://www.oreilly.com/library/view/r-for-data/9781491910382/assets/rfds_00in01.png\" />\n",
    "\n",
    "From [Productionizing Machine Learning with Delta Lake](https://databricks.com/blog/2019/08/14/productionizing-machine-learning-with-delta-lake.html):\n",
    "\n",
    "> ## Building a Machine Learning Data Pipeline with Delta Lake\n",
    "> ### Multi-Hop Architecture\n",
    ">\n",
    "> A common architecture uses tables that correspond to different quality levels in the data engineering pipeline, progressively adding structure to the data: data ingestion (“Bronze” tables), transformation/feature engineering (“Silver” tables), and machine learning training or prediction (“Gold” tables). Combined, we refer to these tables as a “multi-hop” architecture. It allows data engineers to build a pipeline that begins with raw data as a “single source of truth” from which everything flows. Subsequent transformations and aggregations can be recalculated and validated to ensure that business-level aggregate tables still reflective the underlying data, even as downstream users refine the data and introduce context-specific structure.\n",
    ">\n",
    "> <img width=\"800\" src=\"https://web.archive.org/web/20201225121125if_/https://databricks.com/wp-content/uploads/2019/08/Delta-Lake-Multi-Hop-Architecture-Overview.png\" alt=\"Delta Architecture diagram showing the process of getting data ready for machine learning.\" />\n",
    ">\n",
    "> It’s worth diving a bit deeper into the analogy of data as water to understand how a Delta Lake pipeline works (if you’ll permit us the extended example). Instead of scheduling a series of distinct batch jobs to move the data through the pipeline in stages, Delta Lake allows data to flow through like water: seamlessly and constantly, in real-time.\n",
    ">\n",
    "> Bronze tables serve as the prototypical lake, where massive amounts of water (data) trickle in continuously. When it arrives, it’s dirty because it comes from different sources, some of which are not so clean. From there, data flows constantly into Silver tables, like the headwaters of a stream connected to the lake, rapidly moving and constantly flowing. As water (or data, in our case) flows downstream, it is cleaned and filtered by the twists and turns of the river, becoming purer as it moves. By the time it reaches the water processing plant downstream (our Gold tables) it receives some final purification and stringent testing to make it ready for consumption, because consumers (in this case, ML algorithms) are very picky and will not tolerate contaminated water. Finally, from the purification plant, it is piped into the faucets of every downstream consumer (be they ML algorithms, or BI analysts), ready for consumption in its purest form.\n",
    "\n",
    "---\n",
    "\n",
    "> *Tidying* your data means storing it in a consistent form that matches the semantics of the dataset with the way it is stored. In brief, when your data is tidy, each column is a variable, and each row is an observation.\n",
    "\n",
    "> Together, tidying and transforming are called *wrangling*, because getting your data in a form that’s natural to work with often feels like a fight!\n",
    "\n",
    "> *Visualization* is a fundamentally human activity. Visualizations can surprise you, but don’t scale particularly well because they require a human to interpret them.\n",
    "\n",
    "> *Models* are complementary tools to visualization. Models are a fundamentally mathematical or computational tool, so they generally scale well. But every model makes assumptions, and by its very nature a model cannot question its own assumptions. That means a model cannot fundamentally surprise you.\n",
    "\n",
    "> The last step of data science is *communication*, an absolutely critical part of any data analysis project. It doesn’t matter how well your models and visualization have led you to understand the data unless you can also communicate your results to others.\n",
    "\n",
    "> The tools you learn in this book will easily handle hundreds of megabytes of data, and with a little care you can typically use them to work with 1–2 Gb of data. If you’re routinely working with larger data (10–100 Gb, say), you should learn more about [data.table](https://github.com/Rdatatable/data.table).\n",
    "\n",
    "> If your data is bigger than this, carefully consider if your big data problem might actually be a small data problem in disguise. While the complete data might be big, often the data needed to answer a specific question is small. You might be able to find a subset, subsample, or summary that fits in memory and still allows you to answer the question that you’re interested in. The challenge here is finding the right small data, which often requires a lot of iteration.\n",
    "\n",
    "> Another possibility is that your big data problem is actually a large number of small data problems. Each individual problem might fit in memory, but you have millions of them. For example, you might want to fit a model to each person in your dataset. That would be trivial if you had just 10 or 100 people, but instead you have a million. Fortunately each problem is independent of the others (a setup that is sometimes called embarrassingly parallel), so you just need a system (like Hadoop or Spark) that allows you to send different datasets to different computers for processing. Once you’ve figured out how to answer the question for a single subset using the tools described in this book, you learn new tools like sparklyr, rhipe, and ddr to solve it for the full dataset.\n",
    "\n",
    "> This flexibility comes with its downsides, but the big upside is how easy it is to evolve tailored grammars for specific parts of the data science process. These mini languages help you think about problems as a data scientist, while supporting fluent interaction between your brain and the computer.\n",
    "\n",
    "> It’s possible to divide data analysis into two camps: hypothesis generation and hypothesis confirmation (sometimes called confirmatory analysis). The focus of this book is unabashedly on hypothesis generation, or data exploration. The complement of hypothesis generation is hypothesis confirmation. The key difference is how often you look at each observation: if you look only once, it’s confirmation; if you look more than once, it’s exploration.\n",
    "\n",
    "> To download R, go to CRAN, the *comprehensive R archive network*. Don’t try and pick a mirror that’s close to you: instead use the cloud mirror, *https://cloud.r-project.org*, which automatically figures it out for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "R packages available\n",
       "\n",
       "Packages in library ‘/usr/local/spark-3.0.1-bin-hadoop3.2/R/lib’:\n",
       "\n",
       "SparkR                  R Front End for 'Apache Spark'\n",
       "\n",
       "Packages in library ‘/opt/conda/lib/R/library’:\n",
       "\n",
       "askpass                 Safe Password Entry for R, Git, and SSH\n",
       "assertthat              Easy Pre and Post Assertions\n",
       "backports               Reimplementations of Functions Introduced Since\n",
       "                        R-3.0.0\n",
       "base                    The R Base Package\n",
       "base64enc               Tools for base64 encoding\n",
       "bitops                  Bitwise Operations\n",
       "blob                    A Simple S3 Class for Representing Vectors of\n",
       "                        Binary Data ('BLOBS')\n",
       "brio                    Basic R Input Output\n",
       "broom                   Convert Statistical Objects into Tidy Tibbles\n",
       "callr                   Call R from R\n",
       "cellranger              Translate Spreadsheet Cell Ranges to Rows and\n",
       "                        Columns\n",
       "cli                     Helpers for Developing Command Line Interfaces\n",
       "clipr                   Read and Write from the System Clipboard\n",
       "codetools               Code Analysis Tools for R\n",
       "colorspace              A Toolbox for Manipulating and Assessing Colors\n",
       "                        and Palettes\n",
       "compiler                The R Compiler Package\n",
       "config                  Manage Environment Specific Configuration\n",
       "                        Values\n",
       "cpp11                   A C++11 Interface for R's C Interface\n",
       "crayon                  Colored Terminal Output\n",
       "curl                    A Modern and Flexible Web Client for R\n",
       "datasets                The R Datasets Package\n",
       "DBI                     R Database Interface\n",
       "dbplyr                  A 'dplyr' Back End for Databases\n",
       "desc                    Manipulate DESCRIPTION Files\n",
       "diffobj                 Diffs for R Objects\n",
       "digest                  Create Compact Hash Digests of R Objects\n",
       "dplyr                   A Grammar of Data Manipulation\n",
       "ellipsis                Tools for Working with ...\n",
       "evaluate                Parsing and Evaluation Tools that Provide More\n",
       "                        Details than the Default\n",
       "fansi                   ANSI Control Sequence Aware String Functions\n",
       "farver                  High Performance Colour Space Manipulation\n",
       "forcats                 Tools for Working with Categorical Variables\n",
       "                        (Factors)\n",
       "forge                   Casting Values into Shape\n",
       "fs                      Cross-Platform File System Operations Based on\n",
       "                        'libuv'\n",
       "gapminder               Data from Gapminder\n",
       "generics                Common S3 Generics not Provided by Base R\n",
       "                        Methods Related to Model Fitting\n",
       "ggplot2                 Create Elegant Data Visualisations Using the\n",
       "                        Grammar of Graphics\n",
       "globals                 Identify Global Objects in R Expressions\n",
       "glue                    Interpreted String Literals\n",
       "graphics                The R Graphics Package\n",
       "grDevices               The R Graphics Devices and Support for Colours\n",
       "                        and Fonts\n",
       "grid                    The Grid Graphics Package\n",
       "gtable                  Arrange 'Grobs' in Tables\n",
       "haven                   Import and Export 'SPSS', 'Stata' and 'SAS'\n",
       "                        Files\n",
       "highr                   Syntax Highlighting for R Source Code\n",
       "hms                     Pretty Time of Day\n",
       "htmltools               Tools for HTML\n",
       "htmlwidgets             HTML Widgets for R\n",
       "httr                    Tools for Working with URLs and HTTP\n",
       "IRdisplay               'Jupyter' Display Machinery\n",
       "IRkernel                Native R Kernel for the 'Jupyter Notebook'\n",
       "isoband                 Generate Isolines and Isobands from Regularly\n",
       "                        Spaced Elevation Grids\n",
       "jsonlite                A Simple and Robust JSON Parser and Generator\n",
       "                        for R\n",
       "knitr                   A General-Purpose Package for Dynamic Report\n",
       "                        Generation in R\n",
       "labeling                Axis Labeling\n",
       "Lahman                  Sean 'Lahman' Baseball Database\n",
       "lattice                 Trellis Graphics for R\n",
       "lifecycle               Manage the Life Cycle of your Package Functions\n",
       "lubridate               Make Dealing with Dates a Little Easier\n",
       "magrittr                A Forward-Pipe Operator for R\n",
       "markdown                Render Markdown with the C Library 'Sundown'\n",
       "MASS                    Support Functions and Datasets for Venables and\n",
       "                        Ripley's MASS\n",
       "Matrix                  Sparse and Dense Matrix Classes and Methods\n",
       "methods                 Formal Methods and Classes\n",
       "mgcv                    Mixed GAM Computation Vehicle with Automatic\n",
       "                        Smoothness Estimation\n",
       "mime                    Map Filenames to MIME Types\n",
       "modelr                  Modelling Functions that Work with the Pipe\n",
       "munsell                 Utilities for Using Munsell Colours\n",
       "nlme                    Linear and Nonlinear Mixed Effects Models\n",
       "nycflights13            Flights that Departed NYC in 2013\n",
       "openssl                 Toolkit for Encryption, Signatures and\n",
       "                        Certificates Based on OpenSSL\n",
       "parallel                Support for Parallel computation in R\n",
       "pbdZMQ                  Programming with Big Data -- Interface to\n",
       "                        'ZeroMQ'\n",
       "pillar                  Coloured Formatting for Columns\n",
       "pkgbuild                Find Tools Needed to Build R Packages\n",
       "pkgconfig               Private Configuration for 'R' Packages\n",
       "pkgload                 Simulate Package Installation and Attach\n",
       "plyr                    Tools for Splitting, Applying and Combining\n",
       "                        Data\n",
       "praise                  Praise Users\n",
       "prettyunits             Pretty, Human Readable Formatting of Quantities\n",
       "processx                Execute and Control System Processes\n",
       "progress                Terminal Progress Bars\n",
       "ps                      List, Query, Manipulate System Processes\n",
       "purrr                   Functional Programming Tools\n",
       "r2d3                    Interface to 'D3' Visualizations\n",
       "R6                      Encapsulated Classes with Reference Semantics\n",
       "rappdirs                Application Directories: Determine Where to\n",
       "                        Save Data, Caches, and Logs\n",
       "RColorBrewer            ColorBrewer Palettes\n",
       "Rcpp                    Seamless R and C++ Integration\n",
       "RCurl                   General Network (HTTP/FTP/...) Client Interface\n",
       "                        for R\n",
       "readr                   Read Rectangular Text Data\n",
       "readxl                  Read Excel Files\n",
       "rematch                 Match Regular Expressions with a Nicer 'API'\n",
       "rematch2                Tidy Output from Regular Expression Matching\n",
       "repr                    Serializable Representations\n",
       "reprex                  Prepare Reproducible Example Code via the\n",
       "                        Clipboard\n",
       "reshape2                Flexibly Reshape Data: A Reboot of the Reshape\n",
       "                        Package\n",
       "rjson                   JSON for R\n",
       "rlang                   Functions for Base Types and Core R and\n",
       "                        'Tidyverse' Features\n",
       "rmarkdown               Dynamic Documents for R\n",
       "rprojroot               Finding Files in Project Subdirectories\n",
       "rstudioapi              Safely Access the RStudio API\n",
       "rvest                   Easily Harvest (Scrape) Web Pages\n",
       "scales                  Scale Functions for Visualization\n",
       "selectr                 Translate CSS Selectors to XPath Expressions\n",
       "sparklyr                R Interface to Apache Spark\n",
       "splines                 Regression Spline Functions and Classes\n",
       "stats                   The R Stats Package\n",
       "stats4                  Statistical Functions using S4 Classes\n",
       "stringi                 Character String Processing Facilities\n",
       "stringr                 Simple, Consistent Wrappers for Common String\n",
       "                        Operations\n",
       "sys                     Powerful and Reliable Tools for Running System\n",
       "                        Commands in R\n",
       "tcltk                   Tcl/Tk Interface\n",
       "testthat                Unit Testing for R\n",
       "tibble                  Simple Data Frames\n",
       "tidyr                   Tidy Messy Data\n",
       "tidyselect              Select from a Set of Strings\n",
       "tidyverse               Easily Install and Load the 'Tidyverse'\n",
       "tinytex                 Helper Functions to Install and Maintain TeX\n",
       "                        Live, and Compile LaTeX Documents\n",
       "tools                   Tools for Package Development\n",
       "utf8                    Unicode Text Processing\n",
       "utils                   The R Utils Package\n",
       "uuid                    Tools for Generating and Handling of UUIDs\n",
       "vctrs                   Vector Helpers\n",
       "viridisLite             Default Color Maps from 'matplotlib' (Lite\n",
       "                        Version)\n",
       "waldo                   Find Differences Between R Objects\n",
       "whisker                 {{mustache}} for R, Logicless Templating\n",
       "withr                   Run Code 'With' Temporarily Modified Global\n",
       "                        State\n",
       "xfun                    Miscellaneous Functions by 'Yihui Xie'\n",
       "xml2                    Parse XML\n",
       "yaml                    Methods to Convert R Data to YAML and Back\n",
       "zeallot                 Multiple, Unpacking, and Destructuring\n",
       "                        Assignment"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── \u001b[1mAttaching packages\u001b[22m ─────────────────────────────────────── tidyverse 1.3.0 ──\n",
      "\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2\u001b[39m 3.3.2     \u001b[32m✔\u001b[39m \u001b[34mpurrr  \u001b[39m 0.3.4\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtibble \u001b[39m 3.0.4     \u001b[32m✔\u001b[39m \u001b[34mdplyr  \u001b[39m 1.0.2\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtidyr  \u001b[39m 1.1.2     \u001b[32m✔\u001b[39m \u001b[34mstringr\u001b[39m 1.4.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mreadr  \u001b[39m 1.4.0     \u001b[32m✔\u001b[39m \u001b[34mforcats\u001b[39m 0.5.0\n",
      "\n",
      "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(tidyverse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In other words, the complement to the tidyverse is not the messyverse, but many other universes of interrelated packages.\n",
    "\n",
    "> If you don’t find anything useful, prepare a minimal reproducible example or **reprex**.\n",
    ">\n",
    "> The easiest way to include data in a question is to use `dput()` to generate the R code to re-create it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "structure(list(mpg = c(21, 21, 22.8, 21.4, 18.7, 18.1, 14.3, \n",
      "24.4, 22.8, 19.2, 17.8, 16.4, 17.3, 15.2, 10.4, 10.4, 14.7, 32.4, \n",
      "30.4, 33.9, 21.5, 15.5, 15.2, 13.3, 19.2, 27.3, 26, 30.4, 15.8, \n",
      "19.7, 15, 21.4), cyl = c(6, 6, 4, 6, 8, 6, 8, 4, 4, 6, 6, 8, \n",
      "8, 8, 8, 8, 8, 4, 4, 4, 4, 8, 8, 8, 8, 4, 4, 4, 8, 6, 8, 4), \n",
      "    disp = c(160, 160, 108, 258, 360, 225, 360, 146.7, 140.8, \n",
      "    167.6, 167.6, 275.8, 275.8, 275.8, 472, 460, 440, 78.7, 75.7, \n",
      "    71.1, 120.1, 318, 304, 350, 400, 79, 120.3, 95.1, 351, 145, \n",
      "    301, 121), hp = c(110, 110, 93, 110, 175, 105, 245, 62, 95, \n",
      "    123, 123, 180, 180, 180, 205, 215, 230, 66, 52, 65, 97, 150, \n",
      "    150, 245, 175, 66, 91, 113, 264, 175, 335, 109), drat = c(3.9, \n",
      "    3.9, 3.85, 3.08, 3.15, 2.76, 3.21, 3.69, 3.92, 3.92, 3.92, \n",
      "    3.07, 3.07, 3.07, 2.93, 3, 3.23, 4.08, 4.93, 4.22, 3.7, 2.76, \n",
      "    3.15, 3.73, 3.08, 4.08, 4.43, 3.77, 4.22, 3.62, 3.54, 4.11\n",
      "    ), wt = c(2.62, 2.875, 2.32, 3.215, 3.44, 3.46, 3.57, 3.19, \n",
      "    3.15, 3.44, 3.44, 4.07, 3.73, 3.78, 5.25, 5.424, 5.345, 2.2, \n",
      "    1.615, 1.835, 2.465, 3.52, 3.435, 3.84, 3.845, 1.935, 2.14, \n",
      "    1.513, 3.17, 2.77, 3.57, 2.78), qsec = c(16.46, 17.02, 18.61, \n",
      "    19.44, 17.02, 20.22, 15.84, 20, 22.9, 18.3, 18.9, 17.4, 17.6, \n",
      "    18, 17.98, 17.82, 17.42, 19.47, 18.52, 19.9, 20.01, 16.87, \n",
      "    17.3, 15.41, 17.05, 18.9, 16.7, 16.9, 14.5, 15.5, 14.6, 18.6\n",
      "    ), vs = c(0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, \n",
      "    0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1), am = c(1, \n",
      "    1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, \n",
      "    0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1), gear = c(4, 4, 4, 3, \n",
      "    3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, 4, 4, 3, 3, 3, \n",
      "    3, 3, 4, 5, 5, 5, 5, 5, 4), carb = c(4, 4, 1, 1, 2, 1, 4, \n",
      "    2, 2, 4, 4, 3, 3, 3, 4, 4, 4, 1, 2, 1, 1, 2, 2, 4, 2, 1, \n",
      "    2, 2, 4, 6, 8, 2)), row.names = c(\"Mazda RX4\", \"Mazda RX4 Wag\", \n",
      "\"Datsun 710\", \"Hornet 4 Drive\", \"Hornet Sportabout\", \"Valiant\", \n",
      "\"Duster 360\", \"Merc 240D\", \"Merc 230\", \"Merc 280\", \"Merc 280C\", \n",
      "\"Merc 450SE\", \"Merc 450SL\", \"Merc 450SLC\", \"Cadillac Fleetwood\", \n",
      "\"Lincoln Continental\", \"Chrysler Imperial\", \"Fiat 128\", \"Honda Civic\", \n",
      "\"Toyota Corolla\", \"Toyota Corona\", \"Dodge Challenger\", \"AMC Javelin\", \n",
      "\"Camaro Z28\", \"Pontiac Firebird\", \"Fiat X1-9\", \"Porsche 914-2\", \n",
      "\"Lotus Europa\", \"Ford Pantera L\", \"Ferrari Dino\", \"Maserati Bora\", \n",
      "\"Volvo 142E\"), class = \"data.frame\")\n"
     ]
    }
   ],
   "source": [
    "dput(mtcars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcars.copy <- structure(list(mpg = c(21, 21, 22.8, 21.4, 18.7, 18.1, 14.3, \n",
    "24.4, 22.8, 19.2, 17.8, 16.4, 17.3, 15.2, 10.4, 10.4, 14.7, 32.4, \n",
    "30.4, 33.9, 21.5, 15.5, 15.2, 13.3, 19.2, 27.3, 26, 30.4, 15.8, \n",
    "19.7, 15, 21.4), cyl = c(6, 6, 4, 6, 8, 6, 8, 4, 4, 6, 6, 8, \n",
    "8, 8, 8, 8, 8, 4, 4, 4, 4, 8, 8, 8, 8, 4, 4, 4, 8, 6, 8, 4), \n",
    "    disp = c(160, 160, 108, 258, 360, 225, 360, 146.7, 140.8, \n",
    "    167.6, 167.6, 275.8, 275.8, 275.8, 472, 460, 440, 78.7, 75.7, \n",
    "    71.1, 120.1, 318, 304, 350, 400, 79, 120.3, 95.1, 351, 145, \n",
    "    301, 121), hp = c(110, 110, 93, 110, 175, 105, 245, 62, 95, \n",
    "    123, 123, 180, 180, 180, 205, 215, 230, 66, 52, 65, 97, 150, \n",
    "    150, 245, 175, 66, 91, 113, 264, 175, 335, 109), drat = c(3.9, \n",
    "    3.9, 3.85, 3.08, 3.15, 2.76, 3.21, 3.69, 3.92, 3.92, 3.92, \n",
    "    3.07, 3.07, 3.07, 2.93, 3, 3.23, 4.08, 4.93, 4.22, 3.7, 2.76, \n",
    "    3.15, 3.73, 3.08, 4.08, 4.43, 3.77, 4.22, 3.62, 3.54, 4.11\n",
    "    ), wt = c(2.62, 2.875, 2.32, 3.215, 3.44, 3.46, 3.57, 3.19, \n",
    "    3.15, 3.44, 3.44, 4.07, 3.73, 3.78, 5.25, 5.424, 5.345, 2.2, \n",
    "    1.615, 1.835, 2.465, 3.52, 3.435, 3.84, 3.845, 1.935, 2.14, \n",
    "    1.513, 3.17, 2.77, 3.57, 2.78), qsec = c(16.46, 17.02, 18.61, \n",
    "    19.44, 17.02, 20.22, 15.84, 20, 22.9, 18.3, 18.9, 17.4, 17.6, \n",
    "    18, 17.98, 17.82, 17.42, 19.47, 18.52, 19.9, 20.01, 16.87, \n",
    "    17.3, 15.41, 17.05, 18.9, 16.7, 16.9, 14.5, 15.5, 14.6, 18.6\n",
    "    ), vs = c(0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, \n",
    "    0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1), am = c(1, \n",
    "    1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, \n",
    "    0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1), gear = c(4, 4, 4, 3, \n",
    "    3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, 4, 4, 3, 3, 3, \n",
    "    3, 3, 4, 5, 5, 5, 5, 5, 4), carb = c(4, 4, 1, 1, 2, 1, 4, \n",
    "    2, 2, 4, 4, 3, 3, 3, 4, 4, 4, 1, 2, 1, 1, 2, 2, 4, 2, 1, \n",
    "    2, 2, 4, 6, 8, 2)), row.names = c(\"Mazda RX4\", \"Mazda RX4 Wag\", \n",
    "\"Datsun 710\", \"Hornet 4 Drive\", \"Hornet Sportabout\", \"Valiant\", \n",
    "\"Duster 360\", \"Merc 240D\", \"Merc 230\", \"Merc 280\", \"Merc 280C\", \n",
    "\"Merc 450SE\", \"Merc 450SL\", \"Merc 450SLC\", \"Cadillac Fleetwood\", \n",
    "\"Lincoln Continental\", \"Chrysler Imperial\", \"Fiat 128\", \"Honda Civic\", \n",
    "\"Toyota Corolla\", \"Toyota Corona\", \"Dodge Challenger\", \"AMC Javelin\", \n",
    "\"Camaro Z28\", \"Pontiac Firebird\", \"Fiat X1-9\", \"Porsche 914-2\", \n",
    "\"Lotus Europa\", \"Ford Pantera L\", \"Ferrari Dino\", \"Maserati Bora\", \n",
    "\"Volvo 142E\"), class = \"data.frame\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "R version 4.0.3 (2020-10-10)\n",
       "Platform: x86_64-conda-linux-gnu (64-bit)\n",
       "Running under: Ubuntu 20.04.1 LTS\n",
       "\n",
       "Matrix products: default\n",
       "BLAS:   /opt/conda/lib/libblas.so.3.9.0\n",
       "LAPACK: /opt/conda/lib/liblapack.so.3.9.0\n",
       "\n",
       "locale:\n",
       " [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n",
       " [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    \n",
       " [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   \n",
       " [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 \n",
       " [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n",
       "[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \n",
       "\n",
       "attached base packages:\n",
       "character(0)\n",
       "\n",
       "other attached packages:\n",
       "[1] tidyverse_1.3.0\n",
       "\n",
       "loaded via a namespace (and not attached):\n",
       " [1] Rcpp_1.0.5        cellranger_1.1.0  pillar_1.4.7      compiler_4.0.3   \n",
       " [5] dbplyr_2.0.0      methods_4.0.3     forcats_0.5.0     base64enc_0.1-3  \n",
       " [9] utils_4.0.3       tools_4.0.3       grDevices_4.0.3   digest_0.6.27    \n",
       "[13] uuid_0.1-4        lubridate_1.7.9.2 jsonlite_1.7.2    evaluate_0.14    \n",
       "[17] lifecycle_0.2.0   tibble_3.0.4      gtable_0.3.0      pkgconfig_2.0.3  \n",
       "[21] rlang_0.4.9       reprex_0.3.0      cli_2.2.0         rstudioapi_0.13  \n",
       "[25] IRdisplay_0.7.0   DBI_1.1.0         IRkernel_1.1.1    haven_2.3.1      \n",
       "[29] withr_2.3.0       stringr_1.4.0     xml2_1.3.2        httr_1.4.2       \n",
       "[33] repr_1.1.0        dplyr_1.0.2       fs_1.5.0          hms_0.5.3        \n",
       "[37] generics_0.1.0    vctrs_0.3.6       graphics_4.0.3    datasets_4.0.3   \n",
       "[41] stats_4.0.3       grid_4.0.3        tidyselect_1.1.0  glue_1.4.2       \n",
       "[45] base_4.0.3        R6_2.5.0          fansi_0.4.1       readxl_1.3.1     \n",
       "[49] pbdZMQ_0.3-4      readr_1.4.0       modelr_0.1.8      purrr_0.3.4      \n",
       "[53] tidyr_1.1.2       ggplot2_3.3.2     magrittr_2.0.1    ps_1.5.0         \n",
       "[57] backports_1.2.1   scales_1.1.1      ellipsis_0.3.1    htmltools_0.5.0  \n",
       "[61] rvest_0.3.6       assertthat_0.2.1  colorspace_2.0-0  stringi_1.5.3    \n",
       "[65] munsell_0.5.0     broom_0.7.3       crayon_1.3.4     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sessionInfo(\"tidyverse\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
